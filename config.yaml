model_list:
################################################################
# Fake anthropic
  - model_name: anthropic/claude-3-5-sonnet-20240620*
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_fake
      metadata: "fake Anthropic Claude 3.5 sonnet 20240620"
    rpm: 3000
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20240620*
      api_base: http://10.78.245.52:9119
      api_key: fake-antropic-key
      litellm_provider: anthropic


################################################################
# ANTHROPIC/Claude 3.5 sonnet-20241022 (v2)
# MAIN dev@vivident.xyz
  - model_name: anthropic/claude-3-5-sonnet-v2
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2__dev
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev
      model_info:
        id: anthropic/claude-3-5-sonnet-v2?api-key@dev

################################################################
# ANTHROPIC/Claude 3.5 sonnet-20240620 (v1)
# MAIN dev@vivident.xyz
  - model_name: anthropic/claude-3-5-sonnet-v1
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1__dev
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev
      model_info:
        id: anthropic/claude-3-5-sonnet-v1?api-key@dev

################################################################
# ANTHROPIC/Claude 3.5 haiku-20241022
# MAIN dev@vivident.xyz
  - model_name: anthropic/claude-3-5-haiku
    model_info:
      id: anthropic_claude_3_5_haiku_20241022__dev
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev
      model_info:
        id: anthropic/claude-3-5-haiku?api-key@dev

################################################################
# ANTHROPIC/Claude 3.5 sonnet-20241022 (v2)
# BACKUP dev_llm_0n
  - model_name: anthropic/claude-3-5-sonnet-v2-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2_backup__dev_llm_01
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev_llm_01@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-3-5-sonnet-v2-backup?api-key@dev_llm_01

  - model_name: anthropic/claude-3-5-sonnet-v2-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2_backup__dev_llm_02
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev_llm_02@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-3-5-sonnet-v2-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-3-5-sonnet-v2-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2_backup__dev_llm_03
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev_llm_03@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-3-5-sonnet-v2-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-3-5-sonnet-v2-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2_backup__dev_llm_04
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev_llm_04@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-3-5-sonnet-v2-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-3-5-sonnet-v2-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20241022_v2_backup__dev_llm_05
      metadata: "Anthropic Claude 3.5 sonnet 20241022 v2, dev_llm_05@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      rpm: 1000
      model_info:
        id: anthropic/claude-3-5-sonnet-v2-backup?api-key@dev_llm_05

################################################################
# ANTHROPIC/Claude 3.5 sonnet-20240620 (v1)
# BACKUP dev_llm_0n
  - model_name: anthropic/claude-3-5-sonnet-v1-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1_backup__dev_llm_01
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev_llm_01@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-3-5-sonnet-v1-backup?api-key@dev_llm_01

  - model_name: anthropic/claude-3-5-sonnet-v1-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1_backup__dev_llm_02
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev_llm_02@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-3-5-sonnet-v1-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-3-5-sonnet-v1-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1_backup__dev_llm_03
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev_llm_03@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-3-5-sonnet-v1-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-3-5-sonnet-v1-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1_backup__dev_llm_04
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev_llm_04@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-3-5-sonnet-v1-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-3-5-sonnet-v1-backup
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_v1_backup__dev_llm_05
      metadata: "Anthropic Claude 3.5 sonnet 20240620 v1, dev_llm_05@vivident.xyz"
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      rpm: 1000
      model_info:
        id: anthropic/claude-3-5-sonnet-v1-backup?api-key@dev_llm_05

################################################################
# ANTHROPIC/Claude 3.5 haiku-20241022
# BACKUP dev_llm_0n

  - model_name: anthropic/claude-3-5-haiku-backup
    model_info:
      id: anthropic_claude_3_5_haiku_20241022_backup__dev_llm_01
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev_llm_01@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-3-5-haiku-backup?api-key@dev_llm_01

  - model_name: anthropic/claude-3-5-haiku-backup
    model_info:
      id: anthropic_claude_3_5_haiku_20241022_backup__dev_llm_02
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev_llm_02@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-3-5-haiku-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-3-5-haiku-backup
    model_info:
      id: anthropic_claude_3_5_haiku_20241022_backup__dev_llm_03
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev_llm_03@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-3-5-haiku-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-3-5-haiku-backup
    model_info:
      id: anthropic_claude_3_5_haiku_20241022_backup__dev_llm_04
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev_llm_04@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-3-5-haiku-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-3-5-haiku-backup
    model_info:
      id: anthropic_claude_3_5_haiku_20241022_backup__dev_llm_05
      metadata: "Anthropic Claude 3.5 haiku 20241022, dev_llm_05@vivident.xyz"
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      model_info:
        id: anthropic/claude-3-5-haiku-backup?api-key@dev_llm_05

################################################################
# BEDROCK/Claude 3.5 sonnet-20241022 (v2)
#
# BEDROCK  |  https://docs.litellm.ai/docs/providers/bedrock#provisioned-throughput-models
  - model_name: bedrock/claude-3-5-sonnet
    model_info:
      id: bedrock_3_5_sonnet_20241022_v2_vivident_us_east_1
      metadata: "Cross Region Inference. 400,000 TPM, 50 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    tpm: 400000
    rpm: 50

    litellm_params:
      model: us.anthropic.claude-3-5-sonnet-20241022-v2:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

  - model_name: bedrock/claude-3-5-sonnet
    model_info:
      id: bedrock_3_5_sonnet_20241022_v2_vivident_us_west_2
      metadata: "Cross Region Inference. 2,000,000 TPM, 250 RPM"
      region: "us-west-2"
      region_qualname: "Oregon"

    tpm: 2000000
    rpm: 250

    litellm_params:
      model: us.anthropic.claude-3-5-sonnet-20241022-v2:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-west-2
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# BEDROCK/Claude 3.5 haiku-20241022
#
# https://github.com/Aider-AI/aider/issues/2262
# https://github.com/BerriAI/litellm/issues/5899#issuecomment-2375360951
  - model_name: bedrock/claude-3-5-haiku
    model_info:
      id: bedrock_3_5_haiku_20241022_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 40,000 TPM, 20 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    tpm: 40000
    rpm: 20

    litellm_params:
      model: us.anthropic.claude-3-5-haiku-20241022-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion
        # https://docs.litellm.ai/docs/proxy/health

  - model_name: bedrock/claude-3-5-haiku
    model_info:
      id: bedrock_3_5_haiku_20241022_v1_vivident_us_west_2
      metadata: "Cross Region Inference. 40,000 TPM, 20 RPM"
      region: "us-west-2"
      region_qualname: "Oregon"

    tpm: 40000
    rpm: 20

    litellm_params:
      model: us.anthropic.claude-3-5-haiku-20241022-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-west-2
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# GEMINI  |  https://docs.litellm.ai/docs/providers/gemini
# https://cloud.google.com/vertex-ai/generative-ai/pricing
# https://cloud.google.com/vertex-ai/generative-ai/docs/quotas
  - model_name: gemini/*
    litellm_params:
      model: gemini/*
      litellm_provider: gemini
      api_key: os.environ/GEMINI_API_KEY__dev_01
      drop_params: true

  - model_name: gemini/gemini-2.0-flash-001
    litellm_params:
      model: gemini/gemini-2.0-flash-001
      litellm_provider: gemini
      api_key: os.environ/GEMINI_API_KEY__dev_01
      drop_params: true
    model_info:
      max_tokens: 8192
      max_input_tokens: 1048576
      max_output_tokens: 8192
      input_cost_per_audio_token: 0.000001
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      mode: chat

################################################################
# VERTEX AI  |  https://docs.litellm.ai/docs/providers/gemini
#   litellm docs |-
#       -  https://docs.litellm.ai/docs/providers/vertex#usage-with-litellm-proxy-server
#       -  https://docs.litellm.ai/docs/providers/vertex#using-gcp-service-account
#       -  https://docs.litellm.ai/docs/providers/vertex#dynamic-params
  - model_name: vertex_ai/*
    litellm_params:
      model: vertex_ai/*
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-east5
  - model_name: vertex_ai/*
    litellm_params:
      model: vertex_ai/*
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: europe-west1
  ################################################################
  - model_name: vertex/gemini-2.0-flash-exp
    litellm_params:
      model: gemini-2.0-flash-exp
      litellm_provider: vertex_ai
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1

  - model_name: vertex/gemini-2.0-flash
    litellm_params:
      model: vertex_ai/gemini-2.0-flash-001
      litellm_provider: vertex_ai
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1

  - model_name: vertex/gemini-1.5-pro
    litellm_params:
      model: gemini-1.5-pro-002
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1

  - model_name: vertex/gemini-1.5-flash
    litellm_params:
      model: gemini-1.5-flash-002
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1

################################################################
# OPENAI
  - model_name: openai/*
    litellm_params:
      model: openai/*
      api_key: os.environ/OPENAI_API_KEY_DEV
      model_info:
        mode: completion

################################################################
# FAKE OpenAI
  - model_name: fake-openai-endpoint
    litellm_params:
      model: openai/fake-gpt-4o-mini
      api_key: fake-key
      api_base: http://fake-llm:8090

  - model_name: fake-openai-endpoint-2
    litellm_params:
      model: openai/my-fake-model
      api_key: my-fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
      stream_timeout: 0.001
      rpm: 1

  - model_name: fake-openai-endpoint-3
    litellm_params:
      model: openai/my-fake-model
      api_key: my-fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
      stream_timeout: 0.001
      rpm: 1000

################################################################
# FAKE Anthropic
  - model_name: anthropic-fake/*
    litellm_params:
      model: anthropic/*
      api_key: fake-key
      api_base: http://fake-llm:8090
      litellm_provider: anthropic


################################################################
# FAKE bedrock
  - model_name: bedrock-fake/*
    litellm_params:
      model: bedrock/*
      api_key: fake-key
      api_base: http://fake-llm:8090
      litellm_provider: bedrock

litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  drop_params: false  # https://docs.litellm.ai/docs/completion/drop_params
  # cache: true          # set cache responses to True, litellm defaults to using a redis cache
  telemetry: False

  num_retries: 1
  allowed_fails: 5

  ssl_verify: false
  # https://docs.litellm.ai/docs/completion/json_mode
  # enable_json_schema_validation: True

  # https://docs.litellm.ai/docs/completion/stream#error-handling---infinite-loops
  # REPEATED_STREAMING_CHUNK_LIMIT: 100 # this overrides the litellm default

  # https://docs.litellm.ai/docs/proxy/configs#load-balancing
  fallbacks:
  # Main Fallbacks
   - {"bedrock/claude-3-5-sonnet": ["anthropic/claude-3-5-sonnet-v2", "anthropic/claude-3-5-sonnet-v2-backup", "anthropic/claude-3-5-sonnet-v1", "anthropic/claude-3-5-sonnet-v1-backup"]}
   - {"bedrock/claude-3-5-haiku": ["anthropic/claude-3-5-haiku-backup"]}
   - {"anthropic/claude-3-5-sonnet-v2": ["anthropic/claude-3-5-sonnet-v2-backup", "anthropic/claude-3-5-sonnet-v1", "anthropic/claude-3-5-sonnet-v1-backup"]}
   - {"anthropic/claude-3-5-sonnet": ["anthropic/claude-3-5-sonnet-v2-backup", "anthropic/claude-3-5-sonnet-v1", "anthropic/claude-3-5-sonnet-v1-backup"]}
   - {"gemini/gemini-2.0-flash-exp": ["gemini/gemini-1.5-flash-latest", "openai/gpt-4o-mini"]}
   - {"anthropic/claude-3-5-haiku": ["anthropic/claude-3-5-haiku-backup"]}
  # Test Anthropic server fallback
  # https://github.com/BerriAI/litellm/blob/main/litellm/litellm_core_utils/exception_mapping_utils.py
   - {"anthropic/claude-3-5-sonnet-20240620-529": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-502": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-500": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-429": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-111": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-112": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-113": ["bedrock/claude-3-5-haiku"]}
   - {"anthropic/claude-3-5-sonnet-20240620-114": ["bedrock/claude-3-5-haiku"]}

  # default_fallbacks: ["bedrock/claude-3-5-haiku"]

  success_callback: ["langfuse"] # OPT
  failure_callback: ["langfuse"]  # list of failure callbacks
  # callbacks: ["logfire"]  # list of callbacks - runs on success and failure
  redact_user_api_key_info: true

  langfuse_default_tags:
  # default tags for Langfuse Logging
    - "cache_hit"
    - "cache_key"
    - "proxy_base_url"
    - "user_api_key_alias"
    - "user_api_key_user_id"
    - "user_api_key_user_email"
    - "user_api_key_team_alias"
    - "semantic-similarity"
    - "proxy_base_url"

router_settings:
  # routing_strategy: usage-based-routing
  routing_strategy: usage-based-routing-v2
  enable_pre_call_checks: true
  cooldown_time: 30

  timeout: 180           # E2E timeout
  stream_timeout: 10     # TTFT timeout

  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD

  model_group_alias:
    "anthropic/claude-3-5-sonnet":      "anthropic/claude-3-5-sonnet-v2"

general_settings:
  # https://docs.litellm.ai/docs/proxy/db_info#how-to-disable-litellm_spendlogs
  # Langfuse 연동이 가능하다면 이것은 필요하지 않음. 또한, Enterprise가 아니면 볼수없다.
  disable_spend_logs: True

  store_model_in_db: True
  proxy_budget_rescheduler_min_time: 60
  proxy_budget_rescheduler_max_time: 64
  proxy_batch_write_at: 1
  database_connection_pool_limit: 10

