model_list:

  - model_name: rotator
  # Sonnet 류는 thinking: enable 하지 않으면 thinking 을 사용하지 않는다.
    litellm_params:
      model: us.anthropic.claude-3-7-sonnet-20250219-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

  - model_name: rotator
  # gemini-2.5-pro-preview 모델은 thinking: disabled를 설정해도 소용이 없다.
  # 따라서, 최소한의 thinking을 위해서
  # "thinking": {"type": "enabled", "budget_tokens": 128}
  # 를 설정해야 한다.
  # 위 값은 필요한 경우 requester가 override 할 수 있다.
  #
  # gemini-2.5-flash-preview 모델은
  # "thinking": {"type": "enabled", "budget_tokens": 0}
  # 을 설정하는 것이 가능하다.
    litellm_params:
      model: gemini/gemini-2.5-pro
      # litellm_provider: gemini
      api_key: os.environ/GEMINI_API_KEY__dev_01
      drop_params: true
      thinking:
        type: enabled
        budget_tokens: 128

################################################################
# Fake anthropic
  - model_name: anthropic/claude-3-5-sonnet-20240620*
    model_info:
      id: anthropic_claude_3_5_sonnet_20240620_fake
      metadata: "fake Anthropic Claude 3.5 sonnet 20240620"
    rpm: 3000
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20240620*
      api_base: http://10.78.245.52:9119
      api_key: fake-antropic-key
      litellm_provider: anthropic


################################################################
# ANTHROPIC/Claude sonnet-4.5
# MAIN
  - model_name: anthropic/claude-sonnet-4-5
    model_info:
      id: anthropic_claude_sonnet_4_5__dev
      metadata: "Anthropic Claude sonnet 4.5, dev_llm_01@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-sonnet-4-5?api-key@dev_llm_01

################################################################
# ANTHROPIC/Claude sonnet 4.0
# MAIN
  - model_name: anthropic/claude-sonnet-4-0
    model_info:
      id: anthropic_claude_sonnet_4_0__dev
      metadata: "Anthropic Claude sonnet 4.0, dev_llm_01@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-sonnet-4-0?api-key@dev_llm_01

################################################################
# ANTHROPIC/Claude haiku 4.5
# MAIN
  - model_name: anthropic/claude-haiku-4-5
    model_info:
      id: anthropic_claude_haiku_4_5__dev
      metadata: "Anthropic Claude haiku 4.5, dev_llm_01@vivident.xyz"
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_01
      model_info:
        id: anthropic/claude-haiku-4-5?api-key@dev_llm_01

################################################################
# ANTHROPIC/Claude sonnet 4.5
# BACKUP dev_llm_0n
  - model_name: anthropic/claude-sonnet-4-5-backup
    model_info:
      id: anthropic_claude_sonnet_4_5_backup__dev_llm_02
      metadata: "Anthropic Claude sonnet 4.5, dev_llm_02@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-sonnet-4-5-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-sonnet-4-5-backup
    model_info:
      id: anthropic_claude_sonnet_4_5_backup__dev_llm_03
      metadata: "Anthropic Claude sonnet 4.5, dev_llm_03@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-sonnet-4-5-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-sonnet-4-5-backup
    model_info:
      id: anthropic_claude_sonnet_4_5_backup__dev_llm_04
      metadata: "Anthropic Claude sonnet 4.5, dev_llm_04@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-sonnet-4-5-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-sonnet-4-5-backup
    model_info:
      id: anthropic_claude_sonnet_4_5_backup__dev_llm_05
      metadata: "Anthropic Claude sonnet 4.5, dev_llm_05@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      rpm: 1000
      model_info:
        id: anthropic/claude-sonnet-4-5-backup?api-key@dev_llm_05
################################################################
# ANTHROPIC/Claude sonnet 4.0
# BACKUP dev_llm_0n

  - model_name: anthropic/claude-sonnet-4-0-backup
    model_info:
      id: anthropic_claude_sonnet_4_backup__dev_llm_02
      metadata: "Anthropic Claude sonnet 4, dev_llm_02@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-sonnet-4-0-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-sonnet-4-0-backup
    model_info:
      id: anthropic_claude_sonnet_4_0_backup__dev_llm_03
      metadata: "Anthropic Claude sonnet 4.0, dev_llm_03@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-sonnet-4-0-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-sonnet-4-0-backup
    model_info:
      id: anthropic_claude_sonnet_4_0_backup__dev_llm_04
      metadata: "Anthropic Claude sonnet 4.0, dev_llm_04@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-sonnet-4-0-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-sonnet-4-0-backup
    model_info:
      id: anthropic_claude_sonnet_4_0_backup__dev_llm_05
      metadata: "Anthropic Claude sonnet 4.0, dev_llm_05@vivident.xyz"
    litellm_params:
      model: anthropic/claude-sonnet-4-0
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      rpm: 1000
      model_info:
        id: anthropic/claude-sonnet-4-0-backup?api-key@dev_llm_05

################################################################
# ANTHROPIC/Claude haiku 4.5
# BACKUP dev_llm_0n

  - model_name: anthropic/claude-haiku-4-5-backup
    model_info:
      id: anthropic_claude_haiku_4_5_backup__dev_llm_02
      metadata: "Anthropic Claude haiku 4.5, dev_llm_02@vivident.xyz"
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_02
      model_info:
        id: anthropic/claude-haiku-4-5-backup?api-key@dev_llm_02

  - model_name: anthropic/claude-haiku-4-5-backup
    model_info:
      id: anthropic_claude_haiku_4_5_backup__dev_llm_03
      metadata: "Anthropic Claude haiku 4.5, dev_llm_03@vivident.xyz"
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_03
      model_info:
        id: anthropic/claude-haiku-4-5-backup?api-key@dev_llm_03

  - model_name: anthropic/claude-haiku-4-5-backup
    model_info:
      id: anthropic_claude_haiku_4_5_backup__dev_llm_04
      metadata: "Anthropic Claude haiku 4.5, dev_llm_04@vivident.xyz"
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_04
      model_info:
        id: anthropic/claude-haiku-4-5-backup?api-key@dev_llm_04

  - model_name: anthropic/claude-haiku-4-5-backup
    model_info:
      id: anthropic_claude_haiku_4_5_backup__dev_llm_05
      metadata: "Anthropic Claude haiku 4.5, dev_llm_05@vivident.xyz"
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY__dev_llm_05
      model_info:
        id: anthropic/claude-haiku-4-5-backup?api-key@dev_llm_05

################################################################
# BEDROCK/Claude sonnet 4.5
#
# BEDROCK  |  https://docs.litellm.ai/docs/providers/bedrock#cross-region-inferencing
  - model_name: bedrock/claude-sonnet-4-5
    model_info:
      id: bedrock_4_5_sonnet_20250929_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 10,000 TPM, 3 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    # tpm: 1000000
    # rpm: 250

    litellm_params:
      model: us.anthropic.claude-sonnet-4-5-20250929-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion


################################################################
# BEDROCK/Claude haiku 4.5
#
  - model_name: bedrock/claude-haiku-4-5
    model_info:
      id: bedrock_4_5_haiku_20251001_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 40,000 TPM, 20 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    litellm_params:
      model: us.anthropic.claude-haiku-4-5-20251001-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# BEDROCK/Claude 4 sonnet-20250514
#
# BEDROCK  |  https://docs.litellm.ai/docs/providers/bedrock#cross-region-inferencing
  - model_name: bedrock/claude-sonnet-4-0
    model_info:
      id: bedrock_4_0_sonnet_20250514_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 10,000 TPM, 3 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    # tpm: 1000000
    # rpm: 250

    litellm_params:
      model: us.anthropic.claude-sonnet-4-20250514-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# BEDROCK/Claude 3.7 sonnet-20250219
#
# BEDROCK  |  https://docs.litellm.ai/docs/providers/bedrock#cross-region-inferencing
  - model_name: bedrock/claude-3-7-sonnet
    model_info:
      id: bedrock_3_7_sonnet_20250219_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 10,000 TPM, 3 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    tpm: 1000000
    rpm: 250

    litellm_params:
      model: us.anthropic.claude-3-7-sonnet-20250219-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

  - model_name: bedrock/claude-3-7-sonnet
    model_info:
      id: bedrock_3_7_sonnet_20250219_v1_vivident_us_west_2
      metadata: "Cross Region Inference. 10,000 TPM, 3 RPM"
      region: "us-west-2"
      region_qualname: "Oregon"

    tpm: 1000000
    rpm: 250

    litellm_params:
      model: us.anthropic.claude-3-7-sonnet-20250219-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-west-2
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# BEDROCK/Claude 3.5 sonnet-20241022 (v2)
#
# BEDROCK  |  https://docs.litellm.ai/docs/providers/bedrock#cross-region-inferencing
  - model_name: bedrock/claude-3-5-sonnet
    model_info:
      id: bedrock_3_5_sonnet_20241022_v2_vivident_us_east_1
      metadata: "Cross Region Inference. 400,000 TPM, 50 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    tpm: 400000
    rpm: 50

    litellm_params:
      model: us.anthropic.claude-3-5-sonnet-20241022-v2:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

  - model_name: bedrock/claude-3-5-sonnet
    model_info:
      id: bedrock_3_5_sonnet_20241022_v2_vivident_us_west_2
      metadata: "Cross Region Inference. 2,000,000 TPM, 250 RPM"
      region: "us-west-2"
      region_qualname: "Oregon"

    tpm: 2000000
    rpm: 250

    litellm_params:
      model: us.anthropic.claude-3-5-sonnet-20241022-v2:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-west-2
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
# BEDROCK/Claude 3.5 haiku-20241022
#
# https://github.com/Aider-AI/aider/issues/2262
# https://github.com/BerriAI/litellm/issues/5899#issuecomment-2375360951
  - model_name: bedrock/claude-3-5-haiku
    model_info:
      id: bedrock_3_5_haiku_20241022_v1_vivident_us_east_1
      metadata: "Cross Region Inference. 40,000 TPM, 20 RPM"
      region: "us-east-1"
      region_qualname: "N. Virginia"

    tpm: 40000
    rpm: 20

    litellm_params:
      model: us.anthropic.claude-3-5-haiku-20241022-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-east-1
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion
        # https://docs.litellm.ai/docs/proxy/health

  - model_name: bedrock/claude-3-5-haiku
    model_info:
      id: bedrock_3_5_haiku_20241022_v1_vivident_us_west_2
      metadata: "Cross Region Inference. 40,000 TPM, 20 RPM"
      region: "us-west-2"
      region_qualname: "Oregon"

    tpm: 40000
    rpm: 20

    litellm_params:
      model: us.anthropic.claude-3-5-haiku-20241022-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: us-west-2
      drop_params: true
      model_info:
        litellm_provider: bedrock
        mode: completion

################################################################
################################################################

################################################################
# GEMINI  |  https://docs.litellm.ai/docs/providers/gemini
# https://cloud.google.com/vertex-ai/generative-ai/pricing
# https://cloud.google.com/vertex-ai/generative-ai/docs/quotas
  - model_name: gemini/*
    litellm_params:
      model: gemini/*
      litellm_provider: gemini
      api_key: os.environ/GEMINI_API_KEY__dev_01
      drop_params: true
      safety_settings:
        - category: HARM_CATEGORY_HARASSMENT
          threshold: BLOCK_MEDIUM_AND_ABOVE
        - category: HARM_CATEGORY_HATE_SPEECH
          threshold: BLOCK_MEDIUM_AND_ABOVE
        - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
          threshold: BLOCK_MEDIUM_AND_ABOVE
        - category: HARM_CATEGORY_DANGEROUS_CONTENT
          threshold: BLOCK_MEDIUM_AND_ABOVE
          # BLOCK_NONE
          # BLOCK_ONLY_HIGH
          # BLOCK_MEDIUM_AND_ABOVE
          # BLOCK_LOW_AND_ABOVE


################################################################
# VERTEX AI  |  https://docs.litellm.ai/docs/providers/vertex
#   litellm docs |-
#       -  https://docs.litellm.ai/docs/providers/vertex#usage-with-litellm-proxy-server
#       -  https://docs.litellm.ai/docs/providers/vertex#using-gcp-service-account
#       -  https://docs.litellm.ai/docs/providers/vertex#dynamic-params
  - model_name: vertex_ai/*
    litellm_params:
      model: vertex_ai/*
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-east5
      drop_params: true

  - model_name: vertex_ai/*
    litellm_params:
      model: vertex_ai/*
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: europe-west1
      drop_params: true

################################################################
# VERTEX AI  Gemini only (location = us-central1)
  - model_name: vertex/*
    litellm_params:
      model: vertex_ai/*
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1
      # drop_params: true
      safety_settings:
        - category: HARM_CATEGORY_HARASSMENT
          threshold: BLOCK_NONE
        - category: HARM_CATEGORY_HATE_SPEECH
          threshold: BLOCK_NONE
        - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
          threshold: BLOCK_NONE
        - category: HARM_CATEGORY_DANGEROUS_CONTENT
          threshold: BLOCK_NONE
          # BLOCK_NONE
          # BLOCK_ONLY_HIGH
          # BLOCK_MEDIUM_AND_ABOVE
          # BLOCK_LOW_AND_ABOVE

  - model_name: gemini-2.5-flash-batch
    litellm_params:
      model: gemini-2.5-flash-preview-04-17
      litellm_provider: vertex_ai
      vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
      vertex_project: os.environ/VERTEX_PROJECT_ID
      vertex_location: us-central1
      drop_params: true
      use_in_pass_through: true
    model_info:
      mode: batch

################################################################
# OPENAI
  - model_name: openai/*
    litellm_params:
      model: openai/*
      api_key: os.environ/OPENAI_API_KEY_DEV
      model_info:
        mode: completion


################################################################
# FAKE OpenAI
  - model_name: fake-openai-endpoint
    litellm_params:
      model: openai/fake-gpt-4o-mini
      api_key: fake-key
      api_base: http://fake-llm:8090

  - model_name: fake-openai-endpoint-2
    litellm_params:
      model: openai/my-fake-model
      api_key: my-fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
      stream_timeout: 0.001
      rpm: 1

  - model_name: fake-openai-endpoint-3
    litellm_params:
      model: openai/my-fake-model
      api_key: my-fake-key
      api_base: https://exampleopenaiendpoint-production.up.railway.app/
      stream_timeout: 0.001
      rpm: 1000

################################################################
# FAKE Anthropic
  - model_name: anthropic-fake/*
    litellm_params:
      model: anthropic/*
      api_key: fake-key
      api_base: http://fake-llm:8090
      litellm_provider: anthropic
      drop_params: true


################################################################
# FAKE bedrock
  - model_name: bedrock-fake/*
    litellm_params:
      model: bedrock/*
      api_key: fake-key
      api_base: http://fake-llm:8090
      litellm_provider: bedrock

################################################################
################################################################
# FILES SETTINGS
files_settings:
#   - custom_llm_provider: vertex_ai
#     api_base: https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/batchPredictionJobs
#     vertex_credentials: os.environ/VERTEX_CREDENTIAL_PATH
#     vertex_project: os.environ/VERTEX_PROJECT_ID
#     vertex_location: us-east5
  - custom_llm_provider: openai
    api_key: os.environ/OPENAI_API_KEY_DEV

################################################################
################################################################
# GUARDRAILS
guardrails:
  # https://docs.litellm.ai/docs/proxy/guardrails/bedrock
  - guardrail_name: "test-guardrail"
    litellm_params:
      guardrail: bedrock
      mode: "during_call"
      # mode: "post_call"
      guardrailIdentifier: k2blhbcmljct
      guardrailVersion: "DRAFT"
      aws_region_name: os.environ/AWS_TEST_GUARDRAIL_REGION

  - guardrail_name: "imagegen-guardrail"
    litellm_params:
      guardrail: bedrock
      mode:
        - "during_call"
        - "post_call"
      guardrailIdentifier: qpk8k2ff0uo9
      guardrailVersion: "DRAFT"
      aws_region_name: os.environ/AWS_TEST_GUARDRAIL_REGION
      # disable_exception_on_block: true

  - guardrail_name: "ifchat-converse-input-guardrail"
    litellm_params:
      guardrail: bedrock
      mode: "during_call"
      # mode: "post_call"
      guardrailIdentifier: l8pxzglgbo0i
      guardrailVersion: "DRAFT"
      aws_region_name: os.environ/AWS_TEST_GUARDRAIL_REGION

  - guardrail_name: "ifchat-general-guardrail"
    litellm_params:
      guardrail: bedrock
      mode:
        - "pre_call"
        # - "during_call"
        # - "post_call"
      guardrailIdentifier: 06aeza14d05z
      guardrailVersion: "DRAFT"
      aws_region_name: os.environ/AWS_TEST_GUARDRAIL_REGION

  - guardrail_name: model-armor-shield
    litellm_params:
      guardrail: model_armor
      mode: post_call
      template_id: test-armour-for-litellm
      project_id: os.environ/VERTEX_PROJECT_ID
      location: us-west1
      credentials: os.environ/GCS_PATH_SERVICE_ACCOUNT
      mask_request_content: true       # Enable request content masking
      mask_response_content: true      # Enable response content masking
      fail_on_error: true             # Fail request if Model Armor errors (default: true)

litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  # post_call_rules: plugins.post_call_rules.my_custom_rule
  # callbacks:
  #   - plugins.custom_callbacks.proxy_handler_instance


  drop_params: true  # https://docs.litellm.ai/docs/completion/drop_params
  # cache: true          # set cache responses to True, litellm defaults to using a redis cache
  telemetry: False

  num_retries: 1
  allowed_fails: 5

  ssl_verify: false
  # https://docs.litellm.ai/docs/completion/json_mode
  # enable_json_schema_validation: True

  # https://docs.litellm.ai/docs/completion/stream#error-handling---infinite-loops
  # REPEATED_STREAMING_CHUNK_LIMIT: 100 # this overrides the litellm default

  # https://docs.litellm.ai/docs/proxy/configs#load-balancing
  fallbacks:
    # Main Fallbacks
    # Error: Not working
    # - {"gemini/gemini-2.5-pro": ["openai/gpt-4.1-mini", "vertex/gemini-2.5-flash"]}
    - vertex/gemini-2.5-pro:
      - vertex/gemini-2.5-flash
      - openai/gpt-4.1-mini
    - vertex/gemini-2.0-flash:
      - vertex/gemini-2.5-flash-lite
      - openai/gpt-4o-mini

  # Test Anthropic server fallback
  # https://github.com/BerriAI/litellm/blob/main/litellm/litellm_core_utils/exception_mapping_utils.py
    - {"anthropic/claude-3-5-sonnet-20240620-529": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-502": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-500": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-429": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-111": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-112": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-113": ["bedrock/claude-haiku-4-5"]}
    - {"anthropic/claude-3-5-sonnet-20240620-114": ["bedrock/claude-haiku-4-5"]}

  # default_fallbacks: ["bedrock/claude-3-5-haiku"]

  success_callback: ["langfuse"] # OPT
  failure_callback: ["langfuse"]  # list of failure callbacks
  # callbacks: ["logfire"]  # list of callbacks - runs on success and failure
  redact_user_api_key_info: true

  langfuse_default_tags:
  # default tags for Langfuse Logging
    - "cache_hit"
    - "cache_key"
    - "proxy_base_url"
    - "user_api_key_alias"
    - "user_api_key_user_id"
    - "user_api_key_user_email"
    - "user_api_key_team_alias"
    - "semantic-similarity"
    - "proxy_base_url"

router_settings:
  # routing_strategy: usage-based-routing
  routing_strategy: usage-based-routing-v2
  enable_pre_call_checks: true
  cooldown_time: 5

  timeout: 180           # E2E timeout
  stream_timeout: 99     # TTFT timeout

  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD

  model_group_alias:
    "anthropic/claude-3-5-sonnet":      "anthropic/claude-3-5-sonnet-v2"

general_settings:
  # https://docs.litellm.ai/docs/proxy/db_info#how-to-disable-litellm_spendlogs
  # Langfuse 연동이 가능하다면 이것은 필요하지 않음. 또한, Enterprise가 아니면 볼수없다.
  disable_spend_logs: True

  store_model_in_db: True
  proxy_budget_rescheduler_min_time: 60
  proxy_budget_rescheduler_max_time: 64
  proxy_batch_write_at: 1
  database_connection_pool_limit: 10

